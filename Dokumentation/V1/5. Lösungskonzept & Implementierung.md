# 5. Lösungskonzept

## Designkonzept & Kernfunktionalitäten

### AI-gestützte Musikanalyse mit Multi-Model-Ansatz

**Essentia Framework als technische Grundlage**  
Unser System basiert auf Essentia, einer Audio-Analyse-Bibliothek des Music Technology Group der Universitat Pompeu Fabra Barcelona. Essentia extrahiert sowohl Low-Level-Features (spektrale Eigenschaften, Rhythmus) als auch High-Level-Semantik über vortrainierte neuronale Netze.

**Discogs-EffNet für DJ-relevante Klassifikation**  
Das zentrale Modell nutzt EfficientNet-Architektur, trainiert auf dem Discogs-Datensatz. Dieser umfasst über 400 Genres mit besonderer Gewichtung elektronischer Musik – ideal für DJ-Anwendungen. Ein entscheidender Vorteil: Der Discogs-Datensatz ist mit über einer Million Releases einer der größten verfügbaren Musikdatensätze und beinhaltet explizit auch Veröffentlichungen, die ausschließlich auf Vinyl erschienen sind. Dadurch deckt das Modell einen breiten historischen Querschnitt ab, von klassischen House- und Techno-Releases der 80er und 90er bis zu aktuellen Produktionen. Statt nur Klassifikationsergebnisse zu verwenden, extrahieren wir die internen 400-dimensionalen Embeddings des Netzwerks.

**Spezialisierte Modelle für verschiedene Musikdimensionen**  
Das System analysiert Musik auf vier Ebenen parallel:
• Genre-Klassifikation: 400+ Kategorien für stilistische Einordnung  
• Mood-Analyse: Emotionale Dimensionen (happy, aggressive, relaxed, sad,...)  
• Instrumenterkennung: Dominante Instrumente über MTG-Jamendo-Modell  
• Spektrale-Analyse: Klangfarbe (bright/dark) und spektrale Eigenschaften

*[Abbildung 5.1: Multi-Model AI-Architektur - Parallele Analyse verschiedener Musikdimensionen]*

### Feature-Extraktion und Datenverarbeitung

**Embedding-basierte Ähnlichkeitsberechnung**  
Die 1280-dimensionalen Embeddings erfassen subtile musikalische Ähnlichkeiten jenseits expliziter Genre-Labels. Ähnliche Embeddings bedeuten meist ähnlich klingende Tracks – ein entscheidender Vorteil gegenüber rein kategoriebasierten Ansätzen.

**Robuste Normalisierung gegen Musiksammlungs-Ungleichgewichte**  
Musiksammlungen weisen natürliche Ungleichgewichte auf. Das System kompensiert diese durch:
• Adaptive Genre-Gewichtung (Style-Features: 1.0, Genre: 0.2, Mood: 0.1)  
• Robuste Normalisierung mit Median und MAD statt Mittelwert/Standardabweichung  
• Separate Behandlung verschiedener Feature-Kategorien

**Augmentation statt vollständige Automation**  
Das System analysiert und schlägt vor, überschreibt aber keine bewussten Nutzerentscheidungen. Die finale kuratorische Kontrolle bleibt beim DJ.

*[Abbildung 5.2: Feature-Extraktion Pipeline - Von Audiodatei zu strukturierten Metadaten]*

### Hybride Visualisierung

**Similarity Mode mit PCA-Dimensionsreduktion**  
Der Similarity-Mode nutzt Principal Component Analysis, um die komplexen, hochdimensionalen Audio-Features auf zwei darstellbare Achsen zu reduzieren. Die PCA identifiziert die Richtungen größter Variation in der Musiksammlung und projiziert ähnliche Tracks in räumliche Nähe.

**Das Interpretationsproblem der PCA-Achsen**  
PCA-Dimensionen sind mathematische Linearkombinationen aller ursprünglichen Features und daher nicht direkt interpretierbar. DJs verstehen nicht, warum bestimmte Tracks räumlich gruppiert sind – die Achsen haben keine offensichtliche musikalische Bedeutung.

**XY-Mode für transparente Exploration**  
Als Lösung entwickelten wir den XY-Mode: DJs wählen explizit, welche extrahierten Features auf X- und Y-Achse dargestellt werden. Vollständig transparent und musikalisch interpretierbar.

**Komplementäre Stärken beider Modi**
• Similarity-Mode: Automatische Gruppenfindung, ungezieltes Entdecken ähnlicher Musik  
• XY-Mode: Gezieltes Erkunden spezifischer Feature-Beziehungen, hypothesis-driven Navigation

*[Abbildung 5.3: Hybride Visualisierung - Similarity Mode vs. XY Mode mit Feature-Kontext]*

### Adaptive Tagging

**Selbstdefinierte Kategorien ohne Software-Limits**  
Das MY TAGS System ermöglicht DJs, ihre eigene Terminologie zu verwenden. Beliebige Tags können als Kategorien oder spezifische Labels erstellt werden – keine vordefinierten Strukturen.

**Lernende Tag-Profile aus Nutzerverhalten**  
Wenn DJs Tracks zu selbsterstellten Tags hinzufügen, analysiert das System die Audio-Features dieser Tracks. Für jedes Tag entsteht ein charakteristisches Profil der assoziierten musikalischen Eigenschaften.

**Automatische Track-Empfehlungen für Custom Tags**  
Basierend auf gelernten Tag-Profilen schlägt das System automatisch passende Tracks aus der Sammlung vor. Die Empfehlungen basieren auf Ähnlichkeit zu bereits kategorisierten Tracks – selbst befüllende intelligente Ordner.

*[Abbildung 5.4: MY TAGS Lernschleife - Von Nutzerverhalten zu personalisierten Empfehlungen]*

## Informationsarchitektur

### Strukturierung der Musikbibliothek (Crates, Tags, Smart Crates)

**Hybride Organisationsansätze**  
Das System organisiert Musik sowohl über eine traditionelle Track-Liste als auch über die räumliche 2D-Visualisierung. DJs können zwischen verschiedenen Ansichten wechseln: Library (alle Tracks), Crate-Ansicht oder Tag-Ansicht.

**Crates und Tags System**  
Crates funktionieren als Container für Tracks und können hierarchisch organisiert werden. Tags ermöglichen eine zusätzliche, überlappende Kategorisierung. Diese Dualität unterstützt verschiedene Organisationsphilosophien und erlaubt Drag & Drop Organisation.

**Smart Crates: Regelbasierte automatische Organisation**  
Das Smart Crate System erweitert traditionelle Crates um intelligente, regelbasierte Funktionalität. DJs können Bedingungen definieren, die automatisch bestimmen, welche Tracks in ein Crate aufgenommen oder ausgeschlossen werden sollen.

*[Abbildung 5.5: Informationsarchitektur - Crates, Tags und Smart Crates Hierarchie]*

### Filter- und Suchfunktionen mit Multi-Kategorie-Support

**Multi-Kategorie Filtering**  
Das implementierte Filter-System unterstützt gleichzeitiges Filtern nach Style-Features, Mood-Features, Instrument-Features, spektralen Eigenschaften und Genres. Filter können kombiniert werden mit UND/ODER-Logik.

**Dynamische Filter-Optionen**  
Die verfügbaren Filter-Optionen werden dynamisch aus den vorhandenen Track-Features generiert. Dies stellt sicher, dass nur tatsächlich vorhandene Eigenschaften als Filter angeboten werden.

*[Abbildung 5.6: Multi-Kategorie Filter-System - UI-Mockup mit kombinierbaren Filteroptionen]*

### Vektordatenbank und Feature-Extraktion-Pipeline

**SQLite Datenbank für lokale Performance**  
Alle extrahierten Features werden in einer lokalen SQLite-Datenbank gespeichert. Style-Features, Instrument-Features und Mood-Features werden als JSON-BLOBs persistiert, während spektrale Features in separaten Spalten abgelegt werden.

**Vektorisierung für Ähnlichkeitssuche**  
Track-Features werden in numerische Vektoren umgewandelt und normalisiert. Diese Vektoren ermöglichen mathematische Ähnlichkeitsberechnungen zwischen Tracks über Cosinus-Ähnlichkeit.

*[Abbildung 5.7: Datenbank-Architektur - SQLite Schema und Vektor-Pipeline für Ähnlichkeitssuche]*

## Designprinzipien

### DJ behält kurative Kontrolle

Unser implementierter Lösungsansatz folgt dem Prinzip der Augmentation: Die automatische Analyse und Visualisierung verstärkt die Fähigkeiten des DJs, ersetzt aber nicht dessen kuratorische Entscheidungen.

Das System analysiert und organisiert, aber der DJ behält die volle Kontrolle über finale Entscheidungen. Filter und Empfehlungen sind Vorschläge, keine Vorgaben. Die räumliche Visualisierung eröffnet neue Perspektiven auf die Musiksammlung, ohne bestehende Organisationsstrukturen zu zerstören.

*[Abbildung 5.8: Augmentation-Prinzip - Vergleich traditioneller vs. AI-unterstützter DJ-Workflows]*

### Adaptive UI für verschiedene Nutzungsszenarien

**Tab-basierte Navigation**  
Die Hauptnavigation erfolgt über Tabs zwischen Track-Liste und Visualisierung. Eine Sidebar bietet Zugang zu Library-Bereichen, Crates und Tags.

**Kontextuelle Aktionen**  
Rechtsklick-Kontextmenüs ermöglichen schnelle Aktionen wie das Hinzufügen zu Crates oder das Erstellen neuer Tags. Drag & Drop unterstützt intuitive Track-Organisation.

**Adaptive Darstellungsmodi**  
Das Interface passt sich an die gewählte Sidebar-Auswahl an. Für jede Track-Sammlung kann zwischen Listen-Ansicht und 2D-Map gewechselt werden, je nachdem ob detaillierte Metadaten oder räumliche Beziehungen im Fokus stehen.

*[Abbildung 5.9: Adaptive UI-Komponenten - Interface-Anpassung für verschiedene Nutzungsszenarien]*

### Interpretierbare vs. automatische Visualisierung

**Interaktive Exploration**  
Die Visualisierung unterstützt Zoom- und Pan-Funktionen sowie Lasso-Selektion für die Auswahl mehrerer Tracks. Ein Lasso-Tool ermöglicht die Auswahl mehrerer Tracks durch Aufziehen einer Auswahlform. Selektierte Tracks können dann als Gruppe zu Crates hinzugefügt oder getaggt werden.

**Audio-Playback Integration**  
Ein Player-Component ermöglicht die Vorhörung von Tracks direkt in der Anwendung. Waveform-Visualisierungen zeigen den Audio-content grafisch an. Tracks können sowohl aus der Liste als auch aus der 2D-Visualisierung heraus abgespielt werden.

*[Abbildung 5.10: Interaktive Visualisierung - Lasso-Selection und Audio-Playback Integration]*

## Technische Implementierung

### Python-Backend für Audio-Analyse + Electron-React-Frontend

**Hybride Desktop-Anwendungsarchitektur**  
Unsere technische Implementierung folgt einer hybriden Architektur: Ein Python-basiertes Backend für Audio-Analyse kombiniert mit einer Electron + React.js Frontend-Anwendung. Diese Trennung ermöglicht die Nutzung spezialisierter Tools für ihre jeweiligen Stärken.

**Electron Framework für Desktop-Integration**  
Electron ermöglicht die Entwicklung nativer Desktop-Anwendungen mit Webtechnologien. Diese Wahl bietet direkten Dateisystem-Zugriff für Musiksammlungen, native OS-Integration für Drag & Drop und die Möglichkeit, ressourcenintensive Audio-Analyse im Hintergrund auszuführen.

**React.js für komponentenbasierte UI-Entwicklung**  
React.js bildet das Fundament unserer Benutzeroberfläche. Die komponentenbasierte Architektur eignet sich ideal für komplexe Interface-Anforderungen: wiederverwendbare Track-Komponenten, dynamische Filter-Panels und interaktive Visualisierungen.

*[Abbildung 5.11: Technische Architektur - Python-Backend + Electron-React-Frontend Integration]*

### Class Balancing und robuste Normalisierung für heterogene Daten

**Herausforderungen unausgewogener Musikdaten**  
Musiksammlungen weisen natürlicherweise unausgewogene Verteilungen auf. Diese Ungleichgewichte können zu verzerrten Ähnlichkeitsberechnungen und Clustering-Ergebnissen führen.

**Adaptive Genre-Gewichtung**  
Das System implementiert kategoriebasierte Gewichtung zur Kompensation unterschiedlicher Feature-Wichtigkeiten:
• Style-Features erhalten höchste Gewichtung (1.0) als primärer Differenzierungsfaktor  
• Genre-Features werden moderat gewichtet (0.2) um Dominanz einzelner Genres zu reduzieren  
• Mood-Features erhalten geringe Gewichtung (0.1) als ergänzende Information

**Robuste Normalisierung gegen Ausreißer**  
Statt Standard-Normalisierung verwendet das System robuste statistische Methoden:
• Median und Median Absolute Deviation (MAD) statt Mittelwert und Standardabweichung  
• Reduziert Einfluss von Ausreißern in Feature-Verteilungen  
• Separate Normalisierung pro Feature-Kategorie für ausgewogene Repräsentation

**Stabile Visualisierung der Musiksammlung**  
Die Visualisierung nutzt PCA (Principal Component Analysis) um komplexe Audio-Features auf zwei darstellbare Dimensionen zu reduzieren. Wichtiger Aspekt: Die Positionen verschiedener Musikstile bleiben an festen Orten auf der Karte – Techno-Tracks befinden sich immer im gleichen Bereich, auch wenn neue Tracks hinzugefügt werden.

*[Abbildung 5.13: Class Balancing und Normalisierung - Robuste Statistiken für stabile Visualisierung]*

